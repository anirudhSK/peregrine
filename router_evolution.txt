Routers or switches (I use these two terms interchangeably) have a long history
starting with the ARPANET. The ARPANET was an experimental computer network
that ran over the telephone lines with the goal of interconnecting computers
across several research sites within the U.S for timesharing their computing
resources. The ARPANET later evolved into the Internet. There were two network
architectures that were in consideration for the ARPANET. The first from Larry
Roberts was to directly connect the computers (also known as hosts) to the
telephone lines and have them handle routing, flow control, and reliability.
The second from Wes Clark was to have a dedicated node at each site called an
Interface Message Processor (IMP), which would communicate over the phone lines
to IMPs at other sites. The hosts would then only have to worry about
communicating with their own IMP.

The second approach won out (Page 565 of the 1970 paper on the IMP) primarily
because it decoupled network functionality into IMP functions (routing,
reliability, congestion control) and host functions (application logic for
generating network messages), allowing them to evolve independently.
Practically this meant hosts, which significantly outnumbered IMPs, weren't
disrupted during network upgrades.  For instance, the carrier phone lines could
be replaced with a different communication technology---or a new routing
protocol could be deployed---by upgrading IMPs alone, without disrupting the
hosts. This made it very easy for new hosts to connect to the ARPANET, and was
critical to the rapid growth of the ARPANET. In the mid 1970s, the same idea
was critical to Kahn and Cerf's vision of internetworking, where many
autonomous networks could be easily interconnected by using gateways without
involving all nodes within each autonomous network.

The IMPs were predecessors to the modern-day router and the original ARPANET
design illustrates {\it why} routers are critical to evolvability: they provide
a form of information hiding where many hosts or many autonomous networks can
easily connect to each other without having to understand every detail about
other hosts or other autonomous networks.

IMPs were minicomputers with special purpose forwarding software, which were
then rebranded as routers. The first IMP designed by Bolt, Beranak, and Newman
(BBN) in 1969 was a ruggedized Honeywell DDP-516 minicomputer
(https://en.wikipedia.org/wiki/Interface_Message_Processor and "The interface
message processor for the ARPA computer network"). This IMP could connect to
multiple host computers, providing them all with access to the ARPANET. The
IMPs were an early form of what we call software routers today: they were
merely software running on top of a general purpose computer. This approach was
necessary for the IMPs because the ARPANET was still in a period of rapid
growth and reloading IMP code as assembly programs on top of a computer was key
to evolving the ARPANET. It was also sufficient because the telephone lines in
the ARPANET were wimpy by modern standards: they didn't exceed 100 kbits/s.

This approach of building routers by programming a minicomputer continued for
at least two decades even as routers evolved from IMPs on the ARPANET to
gateways for interconnecting networks to campus routers. Examples include David
Mills' Fuzzball router that provided the NSFNET (the successor to the ARPANET
in 1986 until 1995, when it evolved into the modern-day Internet) 56-kbit
routing backbonne. The Fuzzball ran atop the PDP-11/73 minicomputers. Other
examples include MIT/Noel Chiappa's C gateway project (1984); Proteon, a
startup out of MIT in the 80s, and William Yeager's "Ships in the Night"
Stanford campus router from 1981, which eventually formed the basis of Cisco in
1987---perhaps, the first large company devoted exclusively to networking.

Software routers were also sufficient during this time frame (roughly 1969 when
the IMPs first surfaced until about 1995). Around 1995, the Internet's
explosive growth in traffic volumes resulted in an urgent demand for faster
routers.  As a result, most routers used in production since then have been
designed using Application-Specific Integrated Circuits (ASICs)---essentially,
{\it switching chips} designed from the ground up, in hardware, for the sole
purpose of switching packets.

Juniper Networks was likely the first router company to use a switching chip
through its M40 router in 1998.  Not surprising, given Juniper founder, Pradeep
Sindhu's background in VLSI design. The M40 was between 10 and 100x faster than
software routers of the time, and was historically important in inducing an
industry-wide move towards switching chips. For instance, to compete with
Juniper's increasing link speeds, CISCO began to invest more heavily in ASIC
development for routers. The M40 was also the first known design to explicitly
decouple the router control plane (the infrequent slow path of the router) from
the data plane (the frequent packet-to-packet fast path of the router).

Since the mid-2000s, the rise of datacenters has led to another shift in router
design. Datacenters represent a growing market for routers/switches. Given the
scale of networks within a datacenter (some estimates peg the number of nodes
with an Amazon datacenter at around a million), it is imperative to
aggressively cut down on costs. This has resulted in the commoditazation of
switching chips, and the rise of "merchant silicon". The term "merchant
silicon" refers to commodity switching chips manufactured at a large scale by
semiconductor/silicon companies such as Broadcom and Marvell that can then be
wrapped into a larger router box by a router vendor such as Dell, Arista,
Cisco, or Juniper.

This is not unlike how Dell wraps a motherboard and sheet metal around Intel's
x86 processor chips to create a server machine. Within the datacenter context,
many datacenter operators prefer buying these commodity switching chips
directly from Broadcom (some estimates suggest that 65% of datacenter switching
chips are Broadcom chips) and then designing their own routing software to
control them, without relying on software provided by router vendors. In many
cases, datacenter operators like Google go as far as designing their own router
boxes as well.

The result is that the router industry has really split into two distinct
industries.  Much of the design of the switching chip itself happens in
dedicated semiconductor design companies such as Broadcom, Marvell, and
Qualcomm. Other router vendor companies build a motherboard and box around
these switching chips and then write router software or a network operating
system to control these chips. Increasingly, even companies such as Cisco and
Juniper that had in-house ASIC design teams have moved increasingly towards
building their routers around switching chips from companies such as Broadcom
in a move to reduce the significant costs associated with in-house ASIC design.

% OpenFlow
% Programmable data planes

% https://en.wikipedia.org/wiki/Pradeep_Sindhu
% https://en.wikipedia.org/wiki/Juniper_M_Series#M40
% Discuss Broadcom, merchant silicon, datacenters, and the like here.
% http://www.bloomberg.com/news/articles/2001-02-06/for-juniper-single-mindedness-wins-the-race
